{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "m = 1000  # number of users\n",
    "n = 1000  # number of items\n",
    "\n",
    "A = np.zeros([m + 1, n + 1])  # user_item rating matrix\n",
    "filled_rating = []\n",
    "item_item_sim = np.zeros([n+1, n+1])\n",
    "user_user_sim = np.zeros([m+1, m+1])\n",
    "random_location = set()\n",
    "path = 'library/' # make it empty in azure notebook\n",
    "\n",
    "tag_dict = dict()\n",
    "tag_set = set()\n",
    "\n",
    "tag_user_sum_mat = {}\n",
    "for u in range(0, m+1):\n",
    "    tag_weight = {}\n",
    "    for tag in tag_set:\n",
    "        tag_weight[tag] = 0\n",
    "    tag_user_sum_mat[u] = tag_weight\n",
    "    \n",
    "tag_user_count_mat = {}\n",
    "for u in range(0, m+1):\n",
    "    tag_weight = {}\n",
    "    for tag in tag_set:\n",
    "        tag_weight[tag] = 0\n",
    "    tag_user_count_mat[u] = tag_weight\n",
    "\n",
    "\n",
    "user_rating_sum = dict()\n",
    "for u in range(0,m+1):\n",
    "    user_rating_sum[u] = 0\n",
    "\n",
    "\n",
    "def gt_col(mat, col):\n",
    "    return mat[:, col]\n",
    "\n",
    "\n",
    "def gt_row(mat, row):\n",
    "    return mat[row, :]\n",
    "\n",
    "\n",
    "def magnitude(v):\n",
    "    return np.linalg.norm(v)\n",
    "\n",
    "\n",
    "def cosine_sim(v1, v2):\n",
    "    return 1 - spatial.distance.cosine(v1, v2)\n",
    "\n",
    "\n",
    "# v: vector , p :projection vector\n",
    "def bool_cast(v, p):\n",
    "    return np.multiply(p.astype(bool),v)\n",
    "    \n",
    "\n",
    "def modified_cosine_sim(v1,v2):\n",
    "    numerator = np.dot(v1, v2)\n",
    "    denominator = magnitude(bool_cast(v1,v2))*magnitude(bool_cast(v2, v1)) \n",
    "    return numerator/denominator\n",
    "\n",
    "\n",
    "def special_divide(numerator, denominator):\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(path + 'user_item.pckl', 'rb')\n",
    "A = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(path + 'filled_rating.pckl', 'rb')\n",
    "filled_rating = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(path + 'user_user_sim.pckl', 'rb')\n",
    "user_user_sim = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(path + 'item_item_sim.pckl', 'rb')\n",
    "item_item_sim = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(path + 'random_location.pckl', 'rb')\n",
    "random_location = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(path + 'tag_dict.pckl', 'rb')\n",
    "tag_dict = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(path + 'tag_set.pckl', 'rb')\n",
    "tag_set = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "f = open(path + 'tag_user_sum_mat.pckl', 'rb')\n",
    "tag_user_sum_mat = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(path + 'tag_user_count_mat.pckl', 'rb')\n",
    "tag_user_count_mat = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(path + 'user_rating_sum.pckl', 'rb')\n",
    "user_rating_sum = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only execute if you want to generate the filled_rating or A matrix\n",
    "sample_data = pd.read_csv(path + \"sampleData.csv\")\n",
    "\n",
    "A = np.zeros([m + 1, n + 1])\n",
    "\n",
    "for row in range(0, sample_data.shape[0]):\n",
    "    i = sample_data['userId'][row]\n",
    "    j = sample_data['movieId'][row]\n",
    "    v = sample_data['rating'][row]\n",
    "    A[i][j] = v\n",
    "    filled_rating.append([i, j, v])\n",
    "\n",
    "user_item_pkl = open(path + 'user_item.pckl', 'wb')\n",
    "pickle.dump(A, user_item_pkl )\n",
    "user_item_pkl.close()\n",
    "\n",
    "filled_rating_pkl = open(path + 'filled_rating.pckl', 'wb')\n",
    "pickle.dump(filled_rating, filled_rating_pkl)\n",
    "filled_rating_pkl.close()\n",
    "\n",
    "np.savetxt(path + \"user_item.csv\", A, delimiter=\",\")  # saving user item rating matrix\n",
    "np.savetxt(path + \"filled_rating.csv\", A, delimiter=\",\") # saving places where the rating is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only execute if you want to generate the item_item_sim\n",
    "item_item_sim = np.zeros([n+1, n+1])\n",
    "\n",
    "for i in range(0, n+1):\n",
    "    for j in range(0, n+1):\n",
    "        v1 = gt_col(A, i)\n",
    "        v2 = gt_col(A, j)\n",
    "        if magnitude(v1) != 0 and magnitude(v2) != 0:\n",
    "            item_item_sim[i][j] = cosine_sim(v1, v2)\n",
    "\n",
    "item_item_sim_pkl = open(path + 'item_item_sim.pckl', 'wb')\n",
    "pickle.dump(item_item_sim, item_item_sim_pkl)\n",
    "item_item_sim_pkl.close()\n",
    "\n",
    "np.savetxt(path + \"item_item_similarity.csv\", item_item_sim, delimiter=\",\") # saving item-item similarit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only execute if you want to generate the user_user_item\n",
    "user_user_sim = np.zeros([m+1, m+1])\n",
    "for i in range(0, m+1):\n",
    "    for j in range(0, m+1):\n",
    "        v1 = gt_row(A, i)\n",
    "        v2 = gt_row(A, j)\n",
    "        if magnitude(v1) != 0 and magnitude(v2) != 0:\n",
    "            user_user_sim[i][j] = cosine_sim(v1, v2)\n",
    "\n",
    "user_user_sim_pkl = open(path + 'user_user_sim.pckl', 'wb')\n",
    "pickle.dump(user_user_sim, user_user_sim_pkl)\n",
    "user_user_sim_pkl.close()\n",
    "\n",
    "np.savetxt(path + \"user_user_similarity.csv\", user_user_sim, delimiter=\",\") # saving user user similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n [0.         1.         0.27084462 ... 0.09492173 0.15947379 0.        ]\n [0.         0.27084462 1.         ... 0.11840056 0.1977887  0.        ]\n ...\n [0.         0.09492173 0.11840056 ... 1.         0.13510553 0.        ]\n [0.         0.15947379 0.1977887  ... 0.13510553 1.         0.        ]\n [0.         0.         0.         ... 0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(user_user_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only execute if you want to generate the user_user_item\n",
    "random_location = set()\n",
    "lth = len(filled_rating)\n",
    "while len(random_location) != int(0.2*lth):\n",
    "    random_location.add(random.randint(1, lth))\n",
    "\n",
    "random_location_pkl = open(path + 'random_location.pckl', 'wb')\n",
    "pickle.dump(random_location, random_location_pkl)\n",
    "random_location_pkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7447538466324093\n"
     ]
    }
   ],
   "source": [
    "# it calculates the accuracy based on the \n",
    "predicted = []\n",
    "actual = []\n",
    "for r in random_location:\n",
    "    location1 = filled_rating[r]\n",
    "    active_user = location1[0]\n",
    "    pred_item = location1[1]\n",
    "    actual_rating = location1[2]\n",
    "    \n",
    "    A[active_user][pred_item] = 0\n",
    "    active_user_item_dot = np.dot(gt_row(A,active_user), gt_row(item_item_sim,pred_item))\n",
    "    similarity_sum = np.sum(np.multiply(gt_row(A,active_user).astype(bool), gt_row(item_item_sim,pred_item)))\n",
    "    if similarity_sum != 0:\n",
    "        p = active_user_item_dot/similarity_sum\n",
    "        predicted.append(p)\n",
    "        actual.append(actual_rating)\n",
    "    A[active_user][pred_item] = actual_rating\n",
    "\n",
    "print(metrics.mean_absolute_error(actual,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only execute if you want to generate the tag set \n",
    "movies_csv = pd.read_csv(path + \"movies.csv\")\n",
    "tag_dict = dict()\n",
    "tag_set = set()\n",
    "for row in range(0, movies_csv.shape[0]):\n",
    "    mid = movies_csv['movieId'][row]\n",
    "    tags = movies_csv['genres'][row]\n",
    "    tag_arr = tags.split('|')\n",
    "    tag_dict[mid] = tag_arr\n",
    "    for t in tag_arr:\n",
    "        tag_set.add(t)\n",
    "        \n",
    "tag_dict_pkl = open(path + 'tag_dict.pckl', 'wb')\n",
    "pickle.dump(tag_dict, tag_dict_pkl)\n",
    "tag_dict_pkl.close()\n",
    "\n",
    "tag_set_pkl = open(path + 'tag_set.pckl', 'wb')\n",
    "pickle.dump(tag_set, tag_set_pkl)\n",
    "tag_set_pkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Adventure', '(no genres listed)', 'Thriller', 'Action', 'Mystery', 'Romance', 'Musical', 'Fantasy', 'War', 'IMAX', 'Comedy', 'Drama', 'Animation', 'Western', 'Horror', 'Children', 'Documentary', 'Film-Noir', 'Sci-Fi', 'Crime'}\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Adventure 3.5\n1 Children 3.5\n1 Fantasy 3.5\n1 Adventure 7.0\n1 Drama 3.5\n1 Fantasy 7.0\n1 Mystery 3.5\n1 Sci-Fi 3.5\n1 Mystery 7.0\n1 Sci-Fi 7.0\n1 Thriller 3.5\n1 Mystery 10.5\n1 Thriller 7.0\n1 Crime 3.5\n1 Mystery 14.0\n1 Thriller 10.5\n1 Action 3.5\n1 Adventure 10.5\n1 Comedy 3.5\n1 Crime 7.0\n1 Action 7.5\n1 Drama 7.5\n1 Romance 4.0\n1 War 4.0\n1 Comedy 7.5\n1 Drama 11.5\n1 Horror 4.0\n1 Action 11.5\n1 Adventure 14.5\n1 Sci-Fi 11.0\n1 Action 15.5\n1 Crime 11.0\n1 Drama 15.5\n1 Thriller 14.5\n1 Comedy 11.5\n1 Crime 15.0\n1 Drama 19.5\n1 Thriller 18.5\n1 Crime 19.0\n1 Drama 23.5\n1 Drama 27.0\n1 Action 19.0\n1 Comedy 15.0\n1 Crime 22.5\n1 Fantasy 10.5\n1 Action 23.0\n1 Sci-Fi 15.0\n1 Thriller 22.5\n1 Action 26.5\n1 Sci-Fi 18.5\n1 Crime 26.0\n1 Horror 7.5\n1 Thriller 26.0\n1 Action 29.5\n1 Adventure 17.5\n1 Fantasy 13.5\n1 Adventure 21.0\n1 Children 7.0\n1 Fantasy 17.0\n1 Musical 3.5\n1 Adventure 24.5\n1 Drama 30.5\n1 Sci-Fi 22.0\n2 Comedy 4.0\n2 Romance 4.0\n2 Drama 5.0\n2 Action 5.0\n2 Comedy 9.0\n2 Horror 5.0\n2 Thriller 5.0\n2 Action 9.0\n2 Drama 9.0\n2 War 4.0\n2 Drama 12.0\n2 Musical 3.0\n2 Action 14.0\n2 Adventure 5.0\n2 Sci-Fi 5.0\n2 Drama 17.0\n2 Romance 9.0\n2 War 9.0\n2 Western 5.0\n2 Drama 20.0\n2 Romance 12.0\n2 Action 19.0\n2 Adventure 10.0\n2 Sci-Fi 10.0\n2 Thriller 10.0\n2 Action 24.0\n2 Sci-Fi 15.0\n2 Thriller 15.0\n2 Action 29.0\n2 Sci-Fi 20.0\n2 Horror 7.0\n2 Thriller 17.0\n2 Action 33.0\n2 Adventure 14.0\n2 Mystery 4.0\n2 Romance 16.0\n2 Thriller 21.0\n"
     ]
    }
   ],
   "source": [
    "# only execute if you want to initialise the tag_user_sum_count\n",
    "# and tag_user_cunt_mat, user_rating_sum\n",
    "\n",
    "tag_user_sum_mat = {}\n",
    "for u in range(0, m+1):\n",
    "    tag_weight = {}\n",
    "    for tag in tag_set:\n",
    "        tag_weight[tag] = 0\n",
    "    tag_user_sum_mat[u] = tag_weight\n",
    "    \n",
    "tag_user_count_mat = {}\n",
    "for u in range(0, m+1):\n",
    "    tag_weight = {}\n",
    "    for tag in tag_set:\n",
    "        tag_weight[tag] = 0\n",
    "    tag_user_count_mat[u] = tag_weight\n",
    "    \n",
    "counter = 100\n",
    "for row_tr in filled_rating:\n",
    "    uid = row_tr[0]\n",
    "    mid = row_tr[1]\n",
    "    val = row_tr[2]\n",
    "    for t in tag_dict[mid]:\n",
    "        tag_user_sum_mat[uid][t] = tag_user_sum_mat[uid][t] + val\n",
    "        if counter > 0 :\n",
    "            counter = counter - 1\n",
    "            print(uid, t, tag_user_sum_mat[uid][t])\n",
    "        tag_user_count_mat[uid][t] = tag_user_count_mat[uid][t] + 1\n",
    "\n",
    "for uid in tag_user_sum_mat.keys():\n",
    "    total = 0\n",
    "    for t in tag_user_sum_mat[uid].keys():\n",
    "        numerator = tag_user_sum_mat[uid][t]\n",
    "        denominator = tag_user_count_mat[uid][t]\n",
    "        total = total + special_divide(numerator, denominator)\n",
    "    user_rating_sum[uid] = total\n",
    "    \n",
    "        \n",
    "tag_user_sum_mat_pkl = open(path + 'tag_user_sum_mat.pckl', 'wb')\n",
    "pickle.dump(tag_user_sum_mat, tag_user_sum_mat_pkl)\n",
    "tag_user_sum_mat_pkl.close()\n",
    "\n",
    "tag_user_count_mat_pkl = open(path + 'tag_user_count_mat.pckl', 'wb')\n",
    "pickle.dump(tag_user_count_mat, tag_user_count_mat_pkl)\n",
    "tag_user_count_mat_pkl.close()\n",
    "\n",
    "user_rating_sum_pkl = open(path + 'user_rating_sum.pckl', 'wb')\n",
    "pickle.dump(user_rating_sum, user_rating_sum_pkl)\n",
    "user_rating_sum_pkl.close()\n",
    "\n",
    "# import csv\n",
    "# \n",
    "# with open('user_rating_sum.csv', 'w') as csv_file:\n",
    "#     writer = csv.writer(csv_file)\n",
    "#     for key, value in user_rating_sum.items():\n",
    "#         print(key,value)\n",
    "#         writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7552272094259934\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "actual = []\n",
    "fact_list = []\n",
    "counter = 500\n",
    "for r in random_location:\n",
    "    location1 = filled_rating[r]\n",
    "    active_user = location1[0]\n",
    "    pred_item = location1[1]\n",
    "    actual_rating = location1[2]\n",
    "    \n",
    "    A[active_user][pred_item] = 0\n",
    "    active_user_item_dot = np.dot(gt_row(A,active_user), gt_row(item_item_sim,pred_item))\n",
    "    similarity_sum = np.sum(np.multiply(gt_row(A,active_user).astype(bool), gt_row(item_item_sim,pred_item)))\n",
    "    if similarity_sum != 0:\n",
    "        p = active_user_item_dot/similarity_sum\n",
    "        factor = 0\n",
    "        for t in tag_dict[mid]:\n",
    "            numerator = tag_user_sum_mat[active_user][t]\n",
    "            denominator = tag_user_count_mat[active_user][t]\n",
    "            factor = max(factor, special_divide(numerator, denominator))\n",
    "            # if counter > 0:\n",
    "            #     print(active_user, t ,numerator, denominator)\n",
    "            #     counter = counter-1\n",
    "        # factor = factor/len(tag_dict[mid])\n",
    "        fact_list.append(factor)\n",
    "        p = 0.5*p+0.5*factor\n",
    "        predicted.append(p)\n",
    "        actual.append(actual_rating)\n",
    "    A[active_user][pred_item] = actual_rating\n",
    "\n",
    "# print(tag_user_sum_mat[2]['Thriller'])\n",
    "print(metrics.mean_absolute_error(actual,predicted))\n",
    "np.savetxt(path + \"fact_list.csv\", fact_list, delimiter=\",\")  # saving user item rating matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing special_divide :\n0\n1.6666666666666667\n------------------------\nTesting bool_cast :\n[2 4 0]\n------------------------\nTesting cosine similarity :\n0.5098499285104608\n------------------------\nTesting magnitude :\n5.385164807134504\n------------------------\nTesting modified cosine similarity :\n14\n[2 4 0]\n4.47213595499958\n5.0990195135927845\n[5 1 0]\n0.6139406135149205\n------------------------\n"
     ]
    }
   ],
   "source": [
    "# test cell\n",
    "\n",
    "print(\"Testing special_divide :\")\n",
    "print(special_divide(5, 0))\n",
    "print(special_divide(5, 3))\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"Testing bool_cast :\")\n",
    "v = np.array([2, 4, 3])\n",
    "p = np.array([5, 1, 0])\n",
    "print(bool_cast(v, p))\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"Testing cosine similarity :\")\n",
    "print(cosine_sim(v, p))\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"Testing magnitude :\")\n",
    "print(magnitude(v))\n",
    "print(\"------------------------\")\n",
    "\n",
    "print(\"Testing modified cosine similarity :\")\n",
    "print(modified_cosine_sim(v,p))\n",
    "print(\"------------------------\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
